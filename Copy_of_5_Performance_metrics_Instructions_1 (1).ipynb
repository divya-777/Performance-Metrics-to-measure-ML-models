{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_5_Performance_metrics_Instructions_1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Performance metrics for the given Models without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# other than these two you should not import any other packages"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "WaFLW7oBQvnt",
        "outputId": "bc43db2b-63c4-4253-86ba-7efde74a84d5"
      },
      "source": [
        "# reading data in 5_a.csv file:\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "df_a = pd.read_csv(\"/content/gdrive/My Drive/5_Performance_metrics/5_a.csv\")\n",
        "\n",
        "print(df_a['y'].value_counts())\n",
        "df_a.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "1.0    10000\n",
            "0.0      100\n",
            "Name: y, dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>proba</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.637387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.635165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.766586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.724564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.889199</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     y     proba\n",
              "0  1.0  0.637387\n",
              "1  1.0  0.635165\n",
              "2  1.0  0.766586\n",
              "3  1.0  0.724564\n",
              "4  1.0  0.889199"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4rSCLNuk0gL"
      },
      "source": [
        "### Function to predict y values using probability scores:\n",
        "\n",
        "ypred=[0 if y_score < 0.5 else 1]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQlpVenMQiWJ"
      },
      "source": [
        "def predict_y(Y, threshold):\n",
        "  pred = []\n",
        "  for i in range(len(Y)):\n",
        "    if Y[i]<threshold:\n",
        "      pred.append(0.0)\n",
        "    else:\n",
        "      pred.append(1.0)\n",
        "  ypred = np.array(pred)\n",
        "  return ypred"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gkIijW5l4MZ"
      },
      "source": [
        "###  Function to compute confusion matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_Eyx1UvtuyL"
      },
      "source": [
        "def confusion_matrix(Y, ypred): \n",
        "  ypred\n",
        "  TN = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "  TP = 0\n",
        "  for i in range(len(Y)):\n",
        "    if Y[i] == 0.0 and ypred[i] == 0.0:\n",
        "      TN +=1\n",
        "    elif Y[i] == 1.0 and ypred[i] == 1.0:\n",
        "      TP +=1\n",
        "    elif Y[i] == 1.0 and ypred[i] == 0.0:\n",
        "      FN +=1\n",
        "    else:\n",
        "      FP +=1\n",
        "  return TN, TP, FN, FP\n",
        "  \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTbZcinzmopo"
      },
      "source": [
        "### Function to compute F1_Score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eujQZRnTvprX"
      },
      "source": [
        "def F1_score(TN,TP,FN,FP):\n",
        "  \n",
        "  # precision: what is the Percentage of actual positives of all the points that the model predicted as positives?\n",
        "  pr = TP/(TP+FP)\n",
        "\n",
        "  # Recall: what is the percentage of points that the model detected correctly as positives of all the actual positive points?\n",
        "  re = TP/(FN+TP)\n",
        "\n",
        "  # F1 SCORE:\n",
        "  F1_score = (2*pr*re)/(pr+re)\n",
        "\n",
        "  return F1_score\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XX9pSCOm1L8"
      },
      "source": [
        "### Function to compute Accuracy_score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2UEntjhxtlU"
      },
      "source": [
        "def Accuracy_score(TN,TP,FN,FP):\n",
        "  Accuracy = (TN+TP)/(TN+FN+FP+TP)\n",
        "  return Accuracy\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BWPtg997b13"
      },
      "source": [
        "### Computing AUC score and other metrics for file 5_a.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3CXd8sPWggj",
        "outputId": "70cb5dbf-f928-469f-875a-fd99be34d60b"
      },
      "source": [
        "prob_score = df_a[\"proba\"].to_numpy()\n",
        "Y = df_a[\"y\"].to_numpy()\n",
        "ypred = predict_y(prob_score, 0.5)\n",
        "\n",
        "# 1. Confusion matrix\n",
        "TN, TP, FN, FP = confusion_matrix(Y, ypred)\n",
        "print(\"TN:\",TN,\"TP:\",TP, \"FN:\",FN,\"FP:\",FP)\n",
        "\n",
        "# 2. Computation of F1 score\n",
        "print(\"F1_score:\", F1_score(TN,TP,FN,FP))\n",
        "\n",
        "\n",
        "# 3. Computation of AUC:\n",
        "# sorting proba_scores\n",
        "prob_s = prob_score.copy()\n",
        "#prob_s.sort()\n",
        "prob_s[::-1].sort()\n",
        "\n",
        "TPR = []\n",
        "FPR = []\n",
        "for e in prob_s:   # let \"e\" be threshold\n",
        "  y_threshold = predict_y(prob_score, e)\n",
        "  TN, TP, FN, FP = confusion_matrix(Y, y_threshold)\n",
        "  TPR.append(TP / (TP + FN))\n",
        "  FPR.append(FP / (FP + TN))\n",
        "tpr_array = np.array(TPR)\n",
        "fpr_array = np.array(FPR)\n",
        "print(\"AUC:\", np.trapz(tpr_array, fpr_array))\n",
        "\n",
        "# 4. Computation of Accuracy score\n",
        "print(\"Accuracy_score:\", Accuracy_score(TN,TP,FN,FP))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TN: 0 TP: 10000 FN: 0 FP: 100\n",
            "F1_score: 0.9950248756218906\n",
            "AUC: 0.48829900000000004\n",
            "Accuracy_score: 0.9900990099009901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BKMoqEbC9qg"
      },
      "source": [
        "### Observation:\n",
        "\n",
        "1. Given data is highly imbalanced i.e, number of positive points >> number of negatives points \n",
        "2. AUC is worse than Random Classifier(0.5) hence we can say this is a bad model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoiT5KuqX3RW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84179aa-9f40-4b7b-90d9-4af2791053cb"
      },
      "source": [
        "df_b = pd.read_csv(\"/content/gdrive/My Drive/5_Performance_metrics/5_b.csv\")\n",
        "df_b['y'].value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    10000\n",
              "1.0      100\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UThmKSkQ7pRo"
      },
      "source": [
        "### Computing AUC score and other metrics for file 5_b.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd0e3da0-5169-4efd-bd43-afe814aa8a67"
      },
      "source": [
        "\n",
        "\n",
        "prob_score = df_b[\"proba\"].to_numpy()\n",
        "Y = df_b[\"y\"].to_numpy()\n",
        "ypred = predict_y(prob_score, 0.5)\n",
        "\n",
        "# 1. Confusion matrix\n",
        "TN, TP, FN, FP = confusion_matrix(Y, ypred)\n",
        "print(\"TN:\",TN,\"TP:\",TP, \"FN:\",FN,\"FP:\",FP)\n",
        "\n",
        "# 2. Computation of F1 score\n",
        "F1_score(TN,TP,FN,FP)\n",
        "print(\"F1_score:\", F1_score(TN,TP,FN,FP))\n",
        "\n",
        "# 3. Computation of AUC\n",
        "prob_s = prob_score.copy()\n",
        "prob_s[::-1].sort()\n",
        "\n",
        "TPR = []\n",
        "FPR = []\n",
        "for e in prob_s:   # let \"e\" be threshold\n",
        "  y_threshold = predict_y(prob_score, e)\n",
        "  TN, TP, FN, FP = confusion_matrix(Y, y_threshold)\n",
        "  TPR.append(TP / (TP + FN))\n",
        "  FPR.append(FP / (FP + TN))\n",
        "tpr_array = np.array(TPR)\n",
        "fpr_array = np.array(FPR)\n",
        "print(\"AUC:\", np.trapz(tpr_array, fpr_array))\n",
        "\n",
        "# 4. Computation of Accuracy score\n",
        "print(\"Accuracy_score:\", Accuracy_score(TN,TP,FN,FP))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TN: 9761 TP: 55 FN: 45 FP: 239\n",
            "F1_score: 0.2791878172588833\n",
            "AUC: 0.9377570000000001\n",
            "Accuracy_score: 0.009900990099009901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-t2aUhqDs5s"
      },
      "source": [
        "### Observation:\n",
        "Given data is highly imbalanced i.e, number of Negative points >> number of positive points.\n",
        "\n",
        "We know the Higher the F1 score the better is the model. with f1_score of 0.28 we can say it is a bad model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXe07C4P78r1"
      },
      "source": [
        "### Computing Metrics for file 5_c.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9007e72e-1aff-4f6c-8c39-5491a5d10a52"
      },
      "source": [
        "df_c = pd.read_csv(\"/content/gdrive/My Drive/5_Performance_metrics/5_c.csv\")\n",
        "print(df_c.head())\n",
        "df_c[\"y\"].value_counts()\n",
        "\n",
        "Y = df_c.loc[:,\"y\"].to_numpy() \n",
        "prob_score = df_c.loc[:,\"prob\"].to_numpy() \n",
        "prob_s = prob_score.copy()\n",
        "prob_s[::-1].sort()\n",
        "\n",
        "#Metric A\n",
        "A = {}\n",
        "for e in prob_s:   # let \"e\" be threshold\n",
        "  y_threshold = predict_y(prob_score, e)\n",
        "  TN, TP, FN, FP = confusion_matrix(Y, y_threshold)\n",
        "  key = e\n",
        "  value = 500*FN + 100*FP\n",
        "  A[key] = value\n",
        "print(\"Lowest A:\", min(A, key=A.get))\n",
        "print(\"Best threshold of probability is [\", min(A, key=A.get),\"] with lowest value of metric A which is\", A[min(A, key=A.get)])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   y      prob\n",
            "0  0  0.458521\n",
            "1  0  0.505037\n",
            "2  0  0.418652\n",
            "3  0  0.412057\n",
            "4  0  0.375579\n",
            "Lowest A: 0.2300390278970873\n",
            "Best threshold of probability is [ 0.2300390278970873 ] with lowest value of metric A which is 141000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PSjDiYX8USt"
      },
      "source": [
        "### Computing Metrics MSE, MAPE and R^2 for file 5_d.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "DhBR44Sgl9W0",
        "outputId": "420610d0-4d79-4f70-d455-8e522dab12ec"
      },
      "source": [
        "df_d = pd.read_csv(\"/content/gdrive/My Drive/5_Performance_metrics/5_d.csv\")\n",
        "print(len(df_d))\n",
        "df_d.head()\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>pred</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>101.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120.0</td>\n",
              "      <td>100.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131.0</td>\n",
              "      <td>113.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>164.0</td>\n",
              "      <td>125.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>154.0</td>\n",
              "      <td>152.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       y   pred\n",
              "0  101.0  100.0\n",
              "1  120.0  100.0\n",
              "2  131.0  113.0\n",
              "3  164.0  125.0\n",
              "4  154.0  152.0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnBSY4nhnMiJ",
        "outputId": "4709f80d-f7a5-4d04-d405-4e375cb2958c"
      },
      "source": [
        "# 1. Mean Square error\n",
        "import math\n",
        "n = len(df_d)\n",
        "y  = df_d[\"y\"].to_numpy()\n",
        "y_pred = df_d[\"pred\"].to_numpy()\n",
        "sum = 0\n",
        "for i in range(n):\n",
        "  sum += math.pow((y[i]-y_pred[i]),2)\n",
        "MSE = 1/n*(sum)\n",
        "print(\"Mean Square Error:\", MSE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 177.16569974554707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SatsPj77sRFI",
        "outputId": "b5f7da7e-aedf-4265-c42b-51e6d835b47e"
      },
      "source": [
        "# 2. Mean Absolute Percentage Error:\n",
        "x = y.copy()\n",
        "x.sort()\n",
        "print(x)\n",
        "\n",
        "y_sum = np.sum(y)\n",
        "sum = 0\n",
        "for i in range(n):\n",
        "  sum += abs(y[i]-y_pred[i])\n",
        "\n",
        "MAPE = (sum/y_sum)*100\n",
        "print('Mean Absolute Percentage Error:',MAPE)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  0.   0.   0. ... 427. 439. 440.]\n",
            "Mean Absolute Percentage Error: 12.91202994009687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1s3LelarvmSr"
      },
      "source": [
        "##### **Observation**:\n",
        "######  Since we see zeros in 'y', mean of y values is used as denomiator instead of y values to calculate MAPE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ho_xJdSkFAT1",
        "outputId": "100a1927-31ed-4d0b-c4fd-d06a07f43125"
      },
      "source": [
        "# R^2 Error:\n",
        "y_mean = (np.sum(y))/n\n",
        "\n",
        "ss_total = 0\n",
        "for i in range(n):\n",
        "  ss_total += math.pow((y[i]-y_mean),2)\n",
        "\n",
        "ss_res = 0\n",
        "for i in range(n):\n",
        "  ss_res += math.pow((y[i]-y_pred[i]),2)\n",
        "\n",
        "R_squared_Error = (1-(ss_res/ss_total))\n",
        "print(\"R^2 Error:\", R_squared_Error )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R^2 Error: 0.9563582786990964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaSKs44xJ83_"
      },
      "source": [
        "##### **Observation**:\n",
        "######  We know that, the closer the R^2 error is to 1 the better the model. Since R^2 error is 0.95 closer to 1, It is a good model. "
      ]
    }
  ]
}