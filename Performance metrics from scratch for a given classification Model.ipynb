{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "4CHb6NE7Qvnc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4rSCLNuk0gL"
   },
   "source": [
    "### Function to predict y values using probability scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "iQlpVenMQiWJ"
   },
   "outputs": [],
   "source": [
    "# Predicting class label from probability scores where ytrue are actual class labels and ypred are predicted class labels\n",
    "def predict_y(ytrue, threshold):\n",
    "  pred = []\n",
    "  for i in range(len(ytrue)):\n",
    "    if ytrue[i]<threshold:\n",
    "      pred.append(0)\n",
    "    else:\n",
    "      pred.append(1)\n",
    "  ypred = np.array(pred)\n",
    "  return ypred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gkIijW5l4MZ"
   },
   "source": [
    "###  Function to compute confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "S_Eyx1UvtuyL"
   },
   "outputs": [],
   "source": [
    "# computing confusion matrix from actual and predicted class labels\n",
    "def confusion_matrix(ytrue, ypred): \n",
    "  ypred\n",
    "  TN = 0\n",
    "  FN = 0\n",
    "  FP = 0\n",
    "  TP = 0\n",
    "  for i in range(len(ytrue)):\n",
    "    if ytrue[i] == 0.0 and ypred[i] == 0.0:\n",
    "      TN +=1\n",
    "    elif ytrue[i] == 1.0 and ypred[i] == 1.0:\n",
    "      TP +=1\n",
    "    elif ytrue[i] == 1.0 and ypred[i] == 0.0:\n",
    "      FN +=1\n",
    "    else:\n",
    "      FP +=1\n",
    "  return TN, TP, FN, FP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTbZcinzmopo"
   },
   "source": [
    "### Function to compute F1_Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "eujQZRnTvprX"
   },
   "outputs": [],
   "source": [
    "def F1_score(TN,TP,FN,FP):\n",
    "  \n",
    "  # precision: what is the Percentage of actual positives of all the points that the model predicted as positives?\n",
    "  pr = TP/(TP+FP)\n",
    "\n",
    "  # Recall: what is the percentage of points that the model detected correctly as positives of all the actual positive points?\n",
    "  re = TP/(FN+TP)\n",
    "\n",
    "  # F1 SCORE:\n",
    "  F1_score = (2*pr*re)/(pr+re)\n",
    "\n",
    "  return F1_score\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XX9pSCOm1L8"
   },
   "source": [
    "### Function to compute Accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "o2UEntjhxtlU"
   },
   "outputs": [],
   "source": [
    "def Accuracy_score(TN,TP,FN,FP):\n",
    "  Accuracy = (TN+TP)/(TN+FN+FP+TP)\n",
    "  return Accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Computation of AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3CXd8sPWggj",
    "outputId": "590df2dc-2759-4c51-8cd2-7bc7ee2a6b0b"
   },
   "outputs": [],
   "source": [
    "# sorting proba_scores\n",
    "prob_s = prob_score.copy()   \n",
    "#prob_s.sort()\n",
    "prob_s[::-1].sort()\n",
    "\n",
    "TPR = []\n",
    "FPR = []\n",
    "for e in prob_s:   # let \"e\" be threshold\n",
    "  y_threshold = predict_y(prob_score, e)\n",
    "  TN, TP, FN, FP = confusion_matrix(Y, y_threshold)\n",
    "  TPR.append(TP / (TP + FN))\n",
    "  FPR.append(FP / (FP + TN))\n",
    "tpr_array = np.array(TPR)\n",
    "fpr_array = np.array(FPR)\n",
    "print(\"AUC:\", np.trapz(tpr_array, fpr_array))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LnBSY4nhnMiJ",
    "outputId": "c0b92e0c-b575-4606-a99f-9cd7e421ff15"
   },
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(len(data)):\n",
    "  sum += math.pow((ytrue[i]-ypred[i]),2)\n",
    "MSE = 1/n*(sum)\n",
    "print(\"Mean Square Error:\", MSE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SatsPj77sRFI",
    "outputId": "f974757e-e28d-4439-f36d-becde8b19458"
   },
   "outputs": [],
   "source": [
    "y_sum = np.sum(ytrue)\n",
    "sum = 0\n",
    "for i in range(len(data)):\n",
    "  sum += abs(ytrue[i]-y_pred[i])\n",
    "\n",
    "MAPE = (sum/y_sum)*100\n",
    "print('Mean Absolute Percentage Error:',MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1s3LelarvmSr"
   },
   "source": [
    "##### **Observation**:\n",
    "######  If we see zeros in 'y', mean of y values is used as denomiator instead of y values to calculate MAPE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R^2 Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ho_xJdSkFAT1",
    "outputId": "09bdc831-8a13-4931-e39f-e7f97d1564b9"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_mean = (np.sum(y))/n\n",
    "\n",
    "ss_total = 0\n",
    "for i in range(n):\n",
    "  ss_total += math.pow((y[i]-y_mean),2)\n",
    "\n",
    "ss_res = 0\n",
    "for i in range(n):\n",
    "  ss_res += math.pow((y[i]-y_pred[i]),2)\n",
    "\n",
    "R_squared_Error = (1-(ss_res/ss_total))\n",
    "print(\"R^2 Error:\", R_squared_Error )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaSKs44xJ83_"
   },
   "source": [
    "##### **Observation**:\n",
    "######  The closer the R^2 error is to 1 the better the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 5_Performance_metrics_Instructions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
